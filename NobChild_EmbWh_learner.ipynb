{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Learner of Pearl & Sprouse to Norwegian Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, importing all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data and subsetting it, checking if the dataset looks ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>source</th>\n",
       "      <th>annotated</th>\n",
       "      <th>wh-word</th>\n",
       "      <th>gap sister</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Tommelise</td>\n",
       "      <td>Det var en gang en kone som så gjerne ville ha...</td>\n",
       "      <td>hvor</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Juleunderet</td>\n",
       "      <td>[CP Hvordan [TP alt sammen [VP begynte __, vet...</td>\n",
       "      <td>hvordan</td>\n",
       "      <td>adjunct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tigeren og bjørn…</td>\n",
       "      <td>«Kom, vi tar en tur til byen, så skal jeg vise...</td>\n",
       "      <td>hvordan</td>\n",
       "      <td>adjunct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Froskeslottet</td>\n",
       "      <td>Jeg husker ikke helt [CP hvor [TP det [VP begy...</td>\n",
       "      <td>hvor</td>\n",
       "      <td>adjunct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Jonas får briller</td>\n",
       "      <td>– Kan du fortelle oss [CP hva [TP __ som [VP s...</td>\n",
       "      <td>hva</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Ikke deg denne gang</td>\n",
       "      <td>Vet pene mennesker [CP hvordan [TP det [VP føl...</td>\n",
       "      <td>hvordan</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Helten</td>\n",
       "      <td>Jeg er så glad for at dere endelig innser [CP ...</td>\n",
       "      <td>hvor fantastisk</td>\n",
       "      <td>V-be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Si aldri farvel</td>\n",
       "      <td>Fortell oss [CP hva [TP __ som [VP hendte i gå...</td>\n",
       "      <td>hva</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Farlig helg</td>\n",
       "      <td>Jeg vet ikke [CP hva [TP det [VP var __ som ve...</td>\n",
       "      <td>hva</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Min venn Zorba</td>\n",
       "      <td>– Jeg vet ikke [CP hva [TP jeg [VP gjør __ hvi...</td>\n",
       "      <td>hva</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   z               source                                          annotated  \\\n",
       "0  2            Tommelise  Det var en gang en kone som så gjerne ville ha...   \n",
       "1  3          Juleunderet  [CP Hvordan [TP alt sammen [VP begynte __, vet...   \n",
       "2  3    Tigeren og bjørn…  «Kom, vi tar en tur til byen, så skal jeg vise...   \n",
       "3  3        Froskeslottet  Jeg husker ikke helt [CP hvor [TP det [VP begy...   \n",
       "4  3    Jonas får briller  – Kan du fortelle oss [CP hva [TP __ som [VP s...   \n",
       "5  3  Ikke deg denne gang  Vet pene mennesker [CP hvordan [TP det [VP føl...   \n",
       "6  3               Helten  Jeg er så glad for at dere endelig innser [CP ...   \n",
       "7  4      Si aldri farvel  Fortell oss [CP hva [TP __ som [VP hendte i gå...   \n",
       "8  4          Farlig helg  Jeg vet ikke [CP hva [TP det [VP var __ som ve...   \n",
       "9  5       Min venn Zorba  – Jeg vet ikke [CP hva [TP jeg [VP gjør __ hvi...   \n",
       "\n",
       "           wh-word gap sister  \n",
       "0             hvor          P  \n",
       "1          hvordan    adjunct  \n",
       "2          hvordan    adjunct  \n",
       "3             hvor    adjunct  \n",
       "4              hva          T  \n",
       "5          hvordan          V  \n",
       "6  hvor fantastisk       V-be  \n",
       "7              hva          T  \n",
       "8              hva          V  \n",
       "9              hva          V  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to open a file, jupyter notebook requires a full path\n",
    "path = 'C:/Users/anastask/OneDrive - NTNU/Project_python_files/Nob_Child/Corpus-NorwegianEmbeddedWh.csv' # edited\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# keeping only some necessary columns\n",
    "data = data[['z', 'source', 'annotated', 'wh-word', 'gap sister']]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a fuction to get container nodes from an annotated string. The function also returns the number of gaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['TP', 'VP']], 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_phrase(annotated):\n",
    "    \"\"\" \n",
    "    takes an annotated row as an input\n",
    "    returns a list of container nodes and a number of gaps\n",
    "    str -> list of lists, int\n",
    "    \"\"\"\n",
    "    phrases = list()\n",
    "    phrases_re = r\"\\b[A-Z][A-Z]+\\b\" # phrases defined as all caps\n",
    "    index_letters = 'iklmo'\n",
    "    indeces = r\"\\{[a-z]\\}\"\n",
    "    d = {}\n",
    "\n",
    "    # assuming curly braces aren't used for anything other than multiple gaps\n",
    "    if '{' not in annotated: # one gap only\n",
    "        matches = re.findall(phrases_re, annotated)\n",
    "        phrases.append(matches[1:]) # all phrases except for the first \n",
    "        n_gaps = 1\n",
    "    # multiple gaps\n",
    "    else:\n",
    "        ind = re.finditer(indeces, annotated)\n",
    "        pos  = [(i.start()+1) for i in ind] # positions of letter indeces\n",
    "        for l in index_letters:\n",
    "            for p in pos:\n",
    "                if l == annotated[p]:\n",
    "                    if l not in d:\n",
    "                        d[l] = [p]\n",
    "                    else:\n",
    "                        d[l].append(p) # dict with indeces and their positions\n",
    "        for v in d.values():\n",
    "            if len(v) == 2: # one gap corresponds to one filler\n",
    "                # subset string between the gap and the filler:\n",
    "                search_string = annotated[v[0]:v[1]] \n",
    "                phrases.append(re.findall(phrases_re, search_string))\n",
    "            else:\n",
    "                # print(annotated)\n",
    "                phrases.append(['CHECKGAP'])\n",
    "        n_gaps = len(d)\n",
    "    return (phrases, n_gaps)\n",
    "\n",
    "# test\n",
    "sentence = 'Her kan du lese [CP hva [TP Fridtjof Nansen [VP skriver ___ om de første skiene sine.'\n",
    "get_phrase(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the dataset row by row, adding two new columns with the container node sequences and the number of gaps. Saving the new dataset (use 'utf-8-sig' to make sure that Norwegian characters are displayed correctly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in data['annotated']:\n",
    "#    print(get_phrase(row))\n",
    "phrases = [get_phrase(r)[0] for r in data['annotated']]\n",
    "n_gaps = [get_phrase(r)[1] for r in data['annotated']]\n",
    "data['c_nodes'] = phrases\n",
    "data['n_gaps'] = n_gaps\n",
    "data.head(10)\n",
    "path = 'C:/Users/anastask/OneDrive - NTNU/Project_python_files/Nob_Child/Corpus-NorwegianEmbeddedWh-edited.csv'\n",
    "data.to_csv(path, index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that inserts 'start' and 'end' nodes to the sequences and splits them into trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('start', 'CP', 'TP'), ('CP', 'TP', 'VP'), ('TP', 'VP', 'end')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_trigrams(cn_seq_arr):\n",
    "    \"\"\"\n",
    "    takes a sequence of container nodes in a form of an array as an input\n",
    "    inserts 'start' and 'end' nodes, makes a list of trigrams and returns it\n",
    "    arr -> list of lists\n",
    "    \"\"\"\n",
    "    cn_seq_arr.insert(0, 'start')\n",
    "    cn_seq_arr.append('end')\n",
    "    trigrams = list(ngrams(cn_seq_arr, 3))\n",
    "    return trigrams\n",
    "\n",
    "# test\n",
    "get_trigrams(['CP', 'TP', 'VP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definig a function that creates a frequency distribution based on a full list of trigrams of container nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_dist(all_trigrams_list):\n",
    "    \"\"\" list of lists -> FreqDist \"\"\"\n",
    "    freq_dist = FreqDist(tr for tr in all_trigrams_list)\n",
    "    # print(freq_dist.max())  # the most frequent trigrams\n",
    "    # print(freq_dist.hapaxes())  # trigrams that occur only once\n",
    "    return freq_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that calculates the probability of a given sequence of container nodes based on the frequency distribution of trigrams of container nodes (with Laplace smoothing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(node_seq, freq_dist):\n",
    "    \"\"\" list, FreqDist -> int (log z-score)\"\"\"\n",
    "    trigrams = get_trigrams(node_seq)\n",
    "    # print(trigrams)\n",
    "    freqs = []\n",
    "    for tr in trigrams:\n",
    "        if tr in freq_dist:\n",
    "            tr_freq = freq_dist.freq(tr)\n",
    "        else:\n",
    "            tr_freq = 1/len(freq_dist) # freq of unattested sequences as 1\n",
    "        freqs.append(tr_freq)\n",
    "    result = math.log(numpy.prod(freqs))\n",
    "    print(node_seq, result, '\\n')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling all the parts together and getting a probability for 3 structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 most common container node trigrams:\n",
      "(('start', 'TP', 'VP'), 9484)\n",
      "(('TP', 'VP', 'end'), 8751)\n",
      "(('TP', 'VP', 'PP'), 553)\n",
      "(('VP', 'PP', 'end'), 518)\n",
      "(('start', 'TP', 'end'), 139)\n",
      "(('VP', 'VP', 'end'), 112)\n",
      "(('TP', 'VP', 'VP'), 100)\n",
      "(('TP', 'VP', 'NP'), 87)\n",
      "(('NP', 'PP', 'end'), 77)\n",
      "(('VP', 'NP', 'PP'), 76)\n",
      "(('VP', 'VP', 'VP'), 51)\n",
      "(('VP', 'PP', 'VP'), 36)\n",
      "(('start', 'TP', 'CP'), 31)\n",
      "(('TP', 'CP', 'end'), 30)\n",
      "(('PP', 'VP', 'end'), 29)\n",
      "\n",
      "\n",
      "['start', 'TP', 'VP', 'end'] -1.604043358121144 \n",
      "\n",
      "['start', 'CP', 'TP', 'VP', 'end'] -14.81693766162948 \n",
      "\n",
      "['start', 'CP', 'TP', 'VP', 'PP', 'end'] -21.24769170830463 \n",
      "\n"
     ]
    }
   ],
   "source": [
    " def main():\n",
    "    all_trigrams = []\n",
    "    for el in data['c_nodes']:\n",
    "        for seq in el:\n",
    "            trigrams = get_trigrams(seq)\n",
    "            for tr in trigrams:\n",
    "                all_trigrams.append(tr)\n",
    "                \n",
    "    freq_dist = get_freq_dist(all_trigrams)\n",
    "    print('15 most common container node trigrams:')\n",
    "    for i in freq_dist.most_common(15):\n",
    "        print(i)\n",
    "        \n",
    "    print('\\n')\n",
    "    get_prob(['TP', 'VP'], freq_dist) # short no island\n",
    "    get_prob(['CP', 'TP', 'VP'], freq_dist) # long no island\n",
    "    get_prob(['CP', 'TP', 'VP', 'PP'], freq_dist) # long island\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
